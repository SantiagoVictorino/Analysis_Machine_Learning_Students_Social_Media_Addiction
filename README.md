# üöÄ Analysis Machine Learning Students Social Media Addiction



**Autor:** Santiago Nahuel Victorino
**Curso:** Data Science
**Fecha:** 10/2025

[![Open In Colab](https://colab.research.google.com/drive/1xwCea1d-5q-M-VJYtyD3yR4aAza7rFWl?usp=sharing)](https://colab.research.google.com/github/SantiagoVictorino/Analysis_Machine_Learning_Students_Social_Media_Addiction/blob/main/[Proyect_Data_Science_Students_Media_Addiction.ipynb)

---

## üìù Descripci√≥n del Proyecto

> This project analyzes a database on the consequences of social media use among students. The objective is to address the influence of average hours of social media use on average hours of sleep per night, building a machine learning model to discover the magnitude of that influence.

---

## üéØ Planteamiento del Problema y Objetivos

### Pregunta de investigaci√≥n
En este proyecto se intentar√° resolver la siguiente pregunta: ¬øQu√© influencia tiene el promedio de horas de uso de las redes sociales diarias sobre el promedio de las horas de sue√±o nocturno?

### Objetivos

1.  **Exploratory Aata Analysis (EDA):** Identificar las caracter√≠sticas y las variables que pueden llegar a ser afectadas por el uso diario de las redes sociales.
2.  **Statistical Analysis:** Hacer un an√°lisis estad√≠stico utilizando el coeficiente de correlaci√≥n r de Pearson para medir la fuerza y direcci√≥n de la relaci√≥n entre las variables.
3.  **Machine Learning model:** Implementar y entrenar un modelo de machine learning para conocer en profundidad la relaci√≥n y determinar que tan significativa es.

---

## üìä Dataset

* **Dataset source:** Kaggle - (https://www.kaggle.com/datasets/adilshamim8/social-media-addiction-vs-relationships).
* **Size** 705 rows x 13 columns.
* **Description:** Cada fila representa un estudiante √∫nico mientras que las columnas indican distintas caracateristicas de cada estudiante como por ejemplo la ubicacion geografica, la edad, el promedio de uso de redes sociales, el promedio de horas de sue√±o nocturnas, etc.

---

## üõ†Ô∏è Tecnolog√≠as Utilizadas

* **Lenguaje:** Python 3.
* **Librer√≠as Principales:**
    * **Pandas:** Para la manipulaci√≥n y limpieza de datos.
    * **NumPy:** Para operaciones num√©ricas eficientes.
    * **Matplotlib & Seaborn:** Para la visualizaci√≥n de datos.
    * **Scikit-learn:** Para el modelado de Machine Learning (preprocesamiento, entrenamiento y evaluaci√≥n).
* **Entorno:** Google Colab

---

## ‚öôÔ∏è Instalaci√≥n y Uso

Explica c√≥mo otra persona puede ejecutar tu proyecto. Dado que usaste Colab, la forma m√°s f√°cil es enlazar directamente a tu notebook.

1.  **Clonar el repositorio (opcional):**
    ```bash
    git clone [https://github.com/](https://github.com/)[TU_USUARIO_GITHUB]/[TU_REPOSITORIO].git
    ```
2.  **Abrir en Google Colab:**
    La forma m√°s sencilla de ejecutar este proyecto es haciendo clic en el siguiente bot√≥n para abrir el notebook directamente en Google Colab:

    [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/[TU_USUARIO_GITHUB]/[TU_REPOSITORIO]/blob/main/[NOMBRE_DE_TU_NOTEBOOK].ipynb)

3.  **Instalar dependencias:**
    Si hay alguna librer√≠a que no venga por defecto en Colab, indica c√≥mo instalarla:
    ```python
    !pip install -r requirements.txt
    ```
    *(Aseg√∫rate de tener un archivo `requirements.txt` en tu repositorio).*

---

## üî¨ Metodolog√≠a: El Paso a Paso

Esta es la secci√≥n m√°s importante. Detalla las fases de tu proyecto de forma clara y ordenada.

### 1. Limpieza y Preprocesamiento de Datos
* Manejo de valores nulos (missing values).
* Correcci√≥n de tipos de datos.
* Codificaci√≥n de variables categ√≥ricas (ej: One-Hot Encoding, Label Encoding).
* Detecci√≥n y tratamiento de outliers (si aplica).

### 2. An√°lisis Exploratorio de Datos (EDA)
* An√°lisis univariado y bivariado para entender la distribuci√≥n de las variables.
* Visualizaci√≥n de las relaciones entre las caracter√≠sticas y la variable objetivo (`Churn`).
* **Incluye aqu√≠ 1 o 2 de tus gr√°ficos m√°s importantes.** Puedes hacer una captura de pantalla del gr√°fico en tu Colab, subirla a tu repositorio de GitHub y enlazarla as√≠:
    ```markdown
    ![Distribuci√≥n de Churn por tipo de contrato](imagenes/grafico1.png)
    ```

### 3. Feature Engineering
* Creaci√≥n de nuevas caracter√≠sticas a partir de las existentes.
* Escalado de datos num√©ricos (ej: StandardScaler, MinMaxScaler).

### 4. Modelado y Entrenamiento
* Divisi√≥n del dataset en conjuntos de entrenamiento y prueba (`train_test_split`).
* Modelos probados (ej: Regresi√≥n Log√≠stica, Random Forest, XGBoost).
* Explicaci√≥n breve de por qu√© elegiste esos modelos.
* Menciona si usaste t√©cnicas como Cross-Validation para asegurar la robustez del modelo.

### 5. Evaluaci√≥n del Modelo
* M√©tricas utilizadas para evaluar el rendimiento (Accuracy, Precisi√≥n, Recall, F1-Score, Curva ROC).
* Presentaci√≥n de los resultados, por ejemplo, con una matriz de confusi√≥n.
    ```markdown
    ![Matriz de Confusi√≥n del Modelo Final](imagenes/matriz_confusion.png)
    ```

---

## üí° Resultados y Conclusiones

Resume los hallazgos clave de tu an√°lisis y el rendimiento de tu modelo final.

* **Resultados del EDA:** ¬øQu√© patrones interesantes encontraste? (Ej: "Los clientes con contratos mes a mes y fibra √≥ptica tienen una tasa de abandono significativamente mayor").
* **Rendimiento del Modelo:** ¬øCu√°l fue el mejor modelo y qu√© m√©tricas obtuvo? (Ej: "El modelo Random Forest alcanz√≥ una precisi√≥n del 82% en el conjunto de prueba").
* **Conclusiones Finales:** ¬øQu√© respondiste de la pregunta de negocio inicial? Ofrece recomendaciones basadas en tus datos.

---

## üöÄ Trabajo Futuro

(Opcional, pero muy recomendado)

Enumera posibles mejoras o siguientes pasos para el proyecto. Esto demuestra que piensas a largo plazo.
* Probar con modelos m√°s complejos (ej: redes neuronales).
* Recolectar m√°s datos para mejorar la predicci√≥n.
* Desplegar el modelo como una API web.

